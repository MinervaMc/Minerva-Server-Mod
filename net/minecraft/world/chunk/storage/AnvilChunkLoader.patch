--- net/minecraft/world/chunk/storage/AnvilChunkLoader.java
+++ net/minecraft/world/chunk/storage/AnvilChunkLoader.java
@@ -1,14 +1,16 @@
 package net.minecraft.world.chunk.storage;
 
-import com.google.common.collect.Maps;
 import java.io.DataInputStream;
 import java.io.DataOutputStream;
 import java.io.File;
 import java.io.IOException;
 import java.util.Collections;
+import java.util.HashMap;
+import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
+import java.util.concurrent.ConcurrentHashMap;
 import javax.annotation.Nullable;
 import net.minecraft.block.Block;
 import net.minecraft.entity.Entity;
@@ -36,17 +38,91 @@
 
 public class AnvilChunkLoader implements IChunkLoader, IThreadedFileIO {
     private static final Logger LOGGER = LogManager.getLogger();
-    private final Map<ChunkPos, NBTTagCompound> chunksToRemove = Maps.<ChunkPos, NBTTagCompound>newConcurrentMap();
-    private final Set<ChunkPos> field_193415_c = Collections.<ChunkPos>newSetFromMap(Maps.newConcurrentMap());
+
+    // removals for MC-119971
+//    private final Map<ChunkPos, NBTTagCompound> chunksToRemove = new ConcurrentHashMap();
+//    private final Set<ChunkPos> pendingAnvilChunksCoordinates = Collections.<ChunkPos>newSetFromMap(new ConcurrentHashMap());
+
+    /* --- new data structures for MC-119971 --- */
+
+    // New data structures don't need to be concurrent since we're doing our
+    // own mutex.  Using the concurrent ones would now just be extra overhead.
+    private final Map<ChunkPos, NBTTagCompound> chunksToRemove = new HashMap();
+
+    // Currently there will never be more than one chunk being written at
+    // one time, but this is convenient and leaves open the future option.
+    private final Map<ChunkPos, NBTTagCompound> chunksInWrite = new HashMap();
+
+    /* --- new synchronized methods for MC-119971 --- */
+
+    // Insert new chunk into pending queue, replacing any older one
+    // at the same position
+    synchronized private void queueChunkToRemove(ChunkPos pos, NBTTagCompound data) {
+        chunksToRemove.put(pos, data);
+
+        // No need to check chunksInWrite.  It may contain an older one
+        // at this location, but what matters is not losing the new one.
+        // This fixes Rich Crosby's bug.
+    }
+
+    // Fetch another chunk to save to disk and atomically move it into
+    // the queue of chunk(s) being written.
+    synchronized private Map.Entry<ChunkPos, NBTTagCompound> fetchChunkToWrite() {
+        if (chunksToRemove.isEmpty()) return null;
+
+        // Pick an entry in chunksToRemove and remove it from the collection
+        Set<Map.Entry<ChunkPos, NBTTagCompound>> entrySet = chunksToRemove.entrySet();
+        Iterator<Map.Entry<ChunkPos, NBTTagCompound>> iter = entrySet.iterator();
+        Map.Entry<ChunkPos, NBTTagCompound> entry = iter.next();
+        iter.remove();
+
+        // Indicate that this entry is going to be written out now
+        chunksInWrite.put(entry.getKey(), entry.getValue());
+
+        return entry;
+    }
+
+    // Once the write for a chunk is completely committed to disk,
+    // this method discards it
+    synchronized private void retireChunkToWrite(ChunkPos pos, NBTTagCompound data) {
+        chunksInWrite.remove(pos);
+    }
+
+    // Check these data structures for a chunk being reloaded
+    synchronized private NBTTagCompound reloadChunkFromRemoveQueues(ChunkPos pos) {
+        // If this chunk is queued at all, the most recent version will be in
+        // chunksToRemove.
+        NBTTagCompound data = chunksToRemove.get(pos);
+
+        // Note:  The above line fetches the chunk but leaves it in the
+        // queue to be saved.  This is the original behavior and probably
+        // safest in terms of avoiding data loss on a crash.  However, if
+        // we wanted to *cancel* the save, replace 'get' with 'remove'.
+
+        // If we found the chunk return it
+        if (data != null) return data;
+
+        // Otherwise, check in chunksInWrite.  This is what fixes
+        // MC-119971.
+        return chunksInWrite.get(pos);
+    }
+
+    // Check if chunk exists at all in any pending save state
+    synchronized private boolean chunkExistInRemoveQueues(ChunkPos pos) {
+        return chunksToRemove.containsKey(pos) || chunksInWrite.containsKey(pos);
+    }
+
+    /* --- end of new code for MC-119971 --- */
+
 
     /** Save directory for chunks using the Anvil format */
     private final File chunkSaveLocation;
-    private final DataFixer field_193416_e;
+    private final DataFixer dataFixer;
     private boolean savingExtraData;
 
     public AnvilChunkLoader(File chunkSaveLocationIn, DataFixer dataFixerIn) {
         this.chunkSaveLocation = chunkSaveLocationIn;
-        this.field_193416_e = dataFixerIn;
+        this.dataFixer = dataFixerIn;
     }
 
     @Nullable
@@ -56,7 +132,9 @@
      */
     public Chunk loadChunk(World worldIn, int x, int z) throws IOException {
         ChunkPos chunkpos = new ChunkPos(x, z);
-        NBTTagCompound nbttagcompound = this.chunksToRemove.get(chunkpos);
+        // deleted line for MC-119971
+//        NBTTagCompound nbttagcompound = (NBTTagCompound)this.chunksToRemove.get(chunkpos);
+        NBTTagCompound nbttagcompound = reloadChunkFromRemoveQueues(chunkpos);  // new for MC-119971
 
         if (nbttagcompound == null) {
             DataInputStream datainputstream = RegionFileCache.getChunkInputStream(this.chunkSaveLocation, x, z);
@@ -65,16 +143,23 @@
                 return null;
             }
 
-            nbttagcompound = this.field_193416_e.process(FixTypes.CHUNK, CompressedStreamTools.read(datainputstream));
+            nbttagcompound = this.dataFixer.process(FixTypes.CHUNK, CompressedStreamTools.read(datainputstream));
+            //System.out.println("Loading chunk " + chunkpos + " from file");
+        } else {
+            //System.out.println("Loading chunk " + chunkpos + " from pending");
         }
 
+
         return this.checkedReadChunkFromNBT(worldIn, x, z, nbttagcompound);
     }
 
+    // This method is in the MCPBot database as "isChunkGeneratedAt"
+    // More than one line of this function is modified for MC-119971
     public boolean func_191063_a(int p_191063_1_, int p_191063_2_) {
         ChunkPos chunkpos = new ChunkPos(p_191063_1_, p_191063_2_);
-        NBTTagCompound nbttagcompound = this.chunksToRemove.get(chunkpos);
-        return nbttagcompound != null ? true : RegionFileCache.func_191064_f(this.chunkSaveLocation, p_191063_1_, p_191063_2_);
+        //NBTTagCompound nbttagcompound = (NBTTagCompound)this.chunksToRemove.get(chunkpos);
+        boolean exists = chunkExistInRemoveQueues(chunkpos);
+        return exists ? true : RegionFileCache.func_191064_f(this.chunkSaveLocation, p_191063_1_, p_191063_2_);
     }
 
     @Nullable
@@ -123,9 +208,14 @@
     }
 
     protected void addChunkToPending(ChunkPos pos, NBTTagCompound compound) {
-        if (!this.field_193415_c.contains(pos)) {
-            this.chunksToRemove.put(pos, compound);
-        }
+        // removed for MC-119971
+//        if (!this.pendingAnvilChunksCoordinates.contains(pos)) {
+//            this.chunksToRemove.put(pos, compound);
+//        }
+
+        // new for MC-119971
+        //System.out.println("Saving chunk " + pos + " to pending");
+        queueChunkToRemove(pos, compound);
 
         ThreadedFileIOBase.getThreadedIOInstance().queueIO(this);
     }
@@ -134,35 +224,72 @@
      * Returns a boolean stating if the write was unsuccessful.
      */
     public boolean writeNextIO() {
-        if (this.chunksToRemove.isEmpty()) {
+        // Removals for MC-119971
+//        if (this.chunksToRemove.isEmpty()) {
+//            if (this.savingExtraData) {
+//                LOGGER.info("ThreadedAnvilChunkStorage ({}): All chunks are saved", new Object[] {this.chunkSaveLocation.getName()});
+//            }
+//
+//            return false;
+//        } else {
+        //ChunkPos chunkpos = (ChunkPos)this.chunksToRemove.keySet().iterator().next();
+
+        // New for MC-119971
+        // Try to fetch a pending chunk
+        Map.Entry<ChunkPos, NBTTagCompound> entry = fetchChunkToWrite();
+        if (entry == null) {
+            // If none left, here's code for some message that will never
+            // be executed since there is no "extra data."
             if (this.savingExtraData) {
                 LOGGER.info("ThreadedAnvilChunkStorage ({}): All chunks are saved", (Object)this.chunkSaveLocation.getName());
             }
 
             return false;
-        } else {
-            ChunkPos chunkpos = this.chunksToRemove.keySet().iterator().next();
-            boolean lvt_3_1_;
-
-            try {
-                this.field_193415_c.add(chunkpos);
-                NBTTagCompound nbttagcompound = this.chunksToRemove.remove(chunkpos);
-
-                if (nbttagcompound != null) {
-                    try {
-                        this.writeChunkData(chunkpos, nbttagcompound);
-                    } catch (Exception exception) {
-                        LOGGER.error("Failed to save chunk", (Throwable)exception);
-                    }
-                }
+        }
 
-                lvt_3_1_ = true;
-            } finally {
-                this.field_193415_c.remove(chunkpos);
-            }
+        // New for MC-119971
+        ChunkPos chunkpos = entry.getKey();
+        NBTTagCompound nbttagcompound = entry.getValue();
+        //System.out.println("Writing chunk " + chunkpos + " to file");
+
+        boolean lvt_3_1_;
+
+        // Removal for MC-119971
+        // Redundant try since writeChunkData is the only thing that can
+        // throw an exception here.
+//            try {
+        // Removal for MC-119971
+        // Noting that a chunk is being written out is handled
+        // already by fetchChunkToWrite and chunk is already
+        // removed from container.
+//                this.pendingAnvilChunksCoordinates.add(chunkpos);
+//                NBTTagCompound nbttagcompound = (NBTTagCompound)this.chunksToRemove.remove(chunkpos);
 
-            return lvt_3_1_;
+        // nbttagcompound can't be null
+        //if (nbttagcompound != null) {
+        try {
+            this.writeChunkData(chunkpos, nbttagcompound);
+        } catch (Exception exception) {
+            LOGGER.error((String)"Failed to save chunk", (Throwable)exception);
         }
+        //}
+
+        lvt_3_1_ = true;
+
+        // Removal for MC-119971
+//            }
+//            finally {
+//                this.pendingAnvilChunksCoordinates.remove(chunkpos);
+//            }
+
+        // New for MC-119971
+        // Now that the chunk is fully committed to disk and any
+        // load would now get it from the RegionFile, we can
+        // retire this chunk from the chunkloader data structures.
+        retireChunkToWrite(chunkpos, nbttagcompound);
+
+        return lvt_3_1_;
+//        }
     }
 
     private void writeChunkData(ChunkPos pos, NBTTagCompound compound) throws IOException {
